{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_point_clouds(point_clouds, titles=None, point_size=1, color_map='gray'):\n",
    "    \"\"\"\n",
    "    Plots multiple 3D point clouds in separate subplots.\n",
    "\n",
    "    Parameters:\n",
    "    - point_clouds: List of 3D point cloud arrays (each Nx3 or Nx4 if with intensity)\n",
    "    - titles: List of titles for each subplot (optional)\n",
    "    - point_size: Size of points in the scatter plot (optional, default=1)\n",
    "    - color_map: Color map to use for point intensity (optional, default='gray')\n",
    "    \"\"\"\n",
    "    num_clouds = len(point_clouds)\n",
    "    fig = plt.figure(figsize=(5 * num_clouds, 5))\n",
    "    \n",
    "    for i, cloud in enumerate(point_clouds):\n",
    "        ax = fig.add_subplot(1, num_clouds, i + 1, projection='3d')\n",
    "        \n",
    "        # Downsample points if needed for visualization\n",
    "        step = max(1, cloud.shape[0] // 1000)  # Adjust to control display density\n",
    "        sample_cloud = cloud[::step]\n",
    "        \n",
    "        if sample_cloud.shape[1] == 3:\n",
    "            ax.scatter(sample_cloud[:, 0], sample_cloud[:, 1], sample_cloud[:, 2], \n",
    "                       s=point_size, c='black')  # No intensity values\n",
    "        elif sample_cloud.shape[1] >= 4:\n",
    "            ax.scatter(sample_cloud[:, 0], sample_cloud[:, 1], sample_cloud[:, 2], \n",
    "                       s=point_size, c=sample_cloud[:, 3], cmap=color_map)  # Use intensity for color\n",
    "\n",
    "        # Set title if provided\n",
    "        if titles and i < len(titles):\n",
    "            ax.set_title(titles[i])\n",
    "            \n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def chamfer_distance(point_cloud1, point_cloud2):\n",
    "    \"\"\"\n",
    "    Computes the Chamfer Distance between two point clouds.\n",
    "\n",
    "    Parameters:\n",
    "    - point_cloud1: Nx3 numpy array of points (first point cloud)\n",
    "    - point_cloud2: Mx3 numpy array of points (second point cloud)\n",
    "\n",
    "    Returns:\n",
    "    - chamfer_dist: Chamfer Distance between point_cloud1 and point_cloud2\n",
    "    \"\"\"\n",
    "    # Build KD-trees for fast nearest-neighbor search\n",
    "    tree1 = cKDTree(point_cloud1)\n",
    "    tree2 = cKDTree(point_cloud2)\n",
    "    \n",
    "    # Nearest neighbor distances from each point in point_cloud1 to point_cloud2\n",
    "    distances1, _ = tree1.query(point_cloud2)\n",
    "    # Nearest neighbor distances from each point in point_cloud2 to point_cloud1\n",
    "    distances2, _ = tree2.query(point_cloud1)\n",
    "    \n",
    "    # Average distances for both directions\n",
    "    chamfer_dist = np.mean(distances1**2) + np.mean(distances2**2)\n",
    "    return chamfer_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.sparse import csgraph\n",
    "\n",
    "def graph_wavelet_transform(point_cloud, k=10):\n",
    "    \"\"\"\n",
    "    Performs a graph wavelet transform on a point cloud using the graph Laplacian.\n",
    "\n",
    "    Parameters:\n",
    "    - point_cloud: Nx3 numpy array of points (e.g., [x, y, z])\n",
    "    - k: Number of nearest neighbors to use for graph construction\n",
    "\n",
    "    Returns:\n",
    "    - transformed: Graph wavelet transformed features (flattened array)\n",
    "    \"\"\"\n",
    "    # Step 1: Construct a k-NN graph from the point cloud\n",
    "    tree = cKDTree(point_cloud)\n",
    "    distances, indices = tree.query(point_cloud, k=k+1)  # k+1 because query includes the point itself\n",
    "    N = point_cloud.shape[0]\n",
    "\n",
    "    # Create adjacency matrix (N x N) based on distances\n",
    "    adjacency_matrix = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(1, k+1):  # Skip the first result, which is the point itself\n",
    "            adjacency_matrix[i, indices[i, j]] = np.exp(-distances[i, j]**2)\n",
    "\n",
    "    # Step 2: Compute the graph Laplacian\n",
    "    laplacian = csgraph.laplacian(adjacency_matrix, normed=True)\n",
    "\n",
    "    # Step 3: Perform the wavelet transform on each point's coordinates\n",
    "    # This uses the eigenvalues and eigenvectors of the Laplacian\n",
    "    eigvals, eigvecs = np.linalg.eigh(laplacian)\n",
    "    wavelet_coeffs = eigvecs @ np.diag(np.exp(-eigvals)) @ eigvecs.T @ point_cloud\n",
    "\n",
    "    # Flatten wavelet coefficients to produce a transformed array\n",
    "    transformed = wavelet_coeffs.flatten()\n",
    "    return transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csgraph\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def inverse_graph_wavelet_transform(transformed, point_cloud_shape, k=10):\n",
    "    \"\"\"\n",
    "    Inverts the graph wavelet transformation on a point cloud, returning it to its original domain.\n",
    "\n",
    "    Parameters:\n",
    "    - transformed: Flattened wavelet-transformed point cloud data\n",
    "    - point_cloud_shape: Tuple (N, 3) representing the original shape of the point cloud\n",
    "    - k: Number of nearest neighbors used in graph construction\n",
    "\n",
    "    Returns:\n",
    "    - original_point_cloud: Reconstructed point cloud (Nx3 array)\n",
    "    \"\"\"\n",
    "    # Reshape the flattened transformed data to match the original point cloud shape\n",
    "    transformed = transformed.reshape(point_cloud_shape)\n",
    "\n",
    "    # Step 1: Reconstruct the graph used in the transform (k-NN adjacency)\n",
    "    tree = cKDTree(transformed)\n",
    "    distances, indices = tree.query(transformed, k=k+1)\n",
    "    N = point_cloud_shape[0]\n",
    "\n",
    "    # Create adjacency matrix\n",
    "    adjacency_matrix = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(1, k+1):\n",
    "            adjacency_matrix[i, indices[i, j]] = np.exp(-distances[i, j]**2)\n",
    "\n",
    "    # Step 2: Compute the Laplacian matrix\n",
    "    laplacian = csgraph.laplacian(adjacency_matrix, normed=True)\n",
    "\n",
    "    # Step 3: Invert the transformation using Laplacian's eigenvalues/eigenvectors\n",
    "    eigvals, eigvecs = np.linalg.eigh(laplacian)\n",
    "    inverse_wavelet_coeffs = eigvecs @ np.diag(np.exp(eigvals)) @ eigvecs.T @ transformed\n",
    "\n",
    "    # Return the reconstructed point cloud in the original domain\n",
    "    return inverse_wavelet_coeffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_l1(transformed, lam):\n",
    "    \"\"\"\n",
    "    Recover sparse representation using L1 regularization for a transformed point cloud.\n",
    "\n",
    "    Parameters:\n",
    "    - transformed: The transformed point cloud data (e.g., after wavelet or graph wavelet transform)\n",
    "    - lam: Regularization parameter (lambda) for controlling sparsity\n",
    "\n",
    "    Returns:\n",
    "    - transformed_recovered: Recovered sparse representation of the point cloud data\n",
    "    \"\"\"\n",
    "    # Apply L1 regularization (soft thresholding) to each dimension of the transformed point cloud\n",
    "    transformed_recovered = np.sign(transformed) * np.maximum(np.abs(transformed) - lam, 0)\n",
    "    return transformed_recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'point_cloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 75\u001b[0m\n\u001b[1;32m     71\u001b[0m         plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m     74\u001b[0m compressive_sensing_point_cloud(\n\u001b[0;32m---> 75\u001b[0m     point_cloud\u001b[38;5;241m=\u001b[39m\u001b[43mpoint_cloud\u001b[49m[:, :\u001b[38;5;241m3\u001b[39m], undersampling_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, lam\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, \n\u001b[1;32m     76\u001b[0m     lam_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, error_function\u001b[38;5;241m=\u001b[39mchamfer_distance, plot_process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, plot_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'point_cloud' is not defined"
     ]
    }
   ],
   "source": [
    "def compressive_sensing_point_cloud(\n",
    "        point_cloud, undersampling_ratio, iter, lam, lam_decay, error_function, \n",
    "        plot_process=False, plot_error=False):\n",
    "    \"\"\"\n",
    "    Compressive sensing on LiDAR point cloud data.\n",
    "    \n",
    "    INPUT:\n",
    "    - point_cloud: Original 3D point cloud data (N x 3 array where N is the number of points)\n",
    "    - undersampling_ratio: Ratio of points to retain during undersampling\n",
    "    - iter: Number of iterations to update the reconstruction\n",
    "    - lam: Regularization parameter for L1 recovery\n",
    "    - lam_decay: Decay factor for lam at each iteration\n",
    "    - error_function: Function for calculating reconstruction error\n",
    "    - plot_process: Boolean to plot the point cloud reconstruction at each iteration\n",
    "    - plot_error: Boolean to plot the error curve over iterations\n",
    "\n",
    "    OUTPUT:\n",
    "    - Plots reconstructed point clouds and error curve if requested.\n",
    "    \"\"\"\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    # Step 1: Randomly undersample the point cloud\n",
    "    num_points = int(len(point_cloud) * undersampling_ratio)\n",
    "    sampled_indices = np.random.choice(len(point_cloud), num_points, replace=False)\n",
    "    point_cloud_undersampled = point_cloud[sampled_indices]\n",
    "\n",
    "    # Initialize the reconstructed point cloud with the undersampled data\n",
    "    point_cloud_reconstructed = point_cloud_undersampled.copy()\n",
    "\n",
    "    if plot_process:\n",
    "        plot_point_clouds([point_cloud, point_cloud_undersampled], \n",
    "                          titles=['Original', 'Undersampled'])\n",
    "\n",
    "    for i in range(iter):\n",
    "        # Apply graph or wavelet transform on the point cloud\n",
    "        transformed_reconstruction = graph_wavelet_transform(point_cloud_reconstructed)\n",
    "\n",
    "        # Recover sparse representation using L1 regularization\n",
    "        transformed_recovered = recover_l1(transformed_reconstruction, lam)\n",
    "\n",
    "        # Inverse transform to return to the 3D spatial domain\n",
    "        point_cloud_reconstructed = inverse_graph_wavelet_transform(transformed_recovered, point_cloud_undersampled.shape)\n",
    "\n",
    "        # Reinforce known (undersampled) points in the reconstruction\n",
    "        point_cloud_reconstructed[sampled_indices] = point_cloud_undersampled\n",
    "\n",
    "        # Compute error between original and reconstructed point clouds\n",
    "        error = error_function(point_cloud, point_cloud_reconstructed)\n",
    "        errors.append(error)\n",
    "\n",
    "        # Decay lambda\n",
    "        lam *= lam_decay\n",
    "\n",
    "        # Plot every 5 iterations if plot_process is enabled\n",
    "        if plot_process and (i + 1) % 5 == 0:\n",
    "            plot_point_clouds([point_cloud, point_cloud_reconstructed], \n",
    "                              titles=['Original', f'Reconstructed (Iter {i + 1})'])\n",
    "\n",
    "    # Plot the reconstruction result\n",
    "    if not plot_process:\n",
    "        plot_point_clouds([point_cloud, point_cloud_undersampled, point_cloud_reconstructed],\n",
    "                          titles=['Original', 'Undersampled', 'Reconstructed'])\n",
    "\n",
    "    # Plot the error convergence\n",
    "    if plot_error:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(errors)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.title('Error Function')\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "compressive_sensing_point_cloud(\n",
    "    point_cloud=point_cloud[:, :3], undersampling_ratio=0.3, iter=1, lam=150, \n",
    "    lam_decay=0.9, error_function=chamfer_distance, plot_process=False, plot_error=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
